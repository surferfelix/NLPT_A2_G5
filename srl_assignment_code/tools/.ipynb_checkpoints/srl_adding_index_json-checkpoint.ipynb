{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6e2b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from typing import List\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccf8c09a-2a46-4552-8ddf-0d5e7ad4dd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_raw_data(raw, file_type):\n",
    "    '''Exports preprocessed raw data file'''\n",
    "  \n",
    "    container = []  # List of lists\n",
    "    with open(raw, encoding = \"utf-8\") as raw_file:\n",
    "        in_raw = csv.reader(raw_file, delimiter='\\t', quotechar='|')\n",
    "        for row in in_raw:\n",
    "            if row:\n",
    "                if row[0].startswith('#'):\n",
    "                    continue\n",
    "                else:\n",
    "                    container.append(row)\n",
    "                      \n",
    "    with open('../data/clean_raw_'+file_type+'_data.tsv', 'w', encoding = \"utf-8\", newline = \"\") as output_file:\n",
    "        writer = csv.writer(output_file, delimiter='\\t', quotechar='|')\n",
    "        # Getting the max line size\n",
    "        padding_limit = max([len(line) for line in container])\n",
    "        sentence_nr = []\n",
    "        line_iter = 0\n",
    "        for line in container:\n",
    "            while len(line) != padding_limit:\n",
    "                line.append('_')\n",
    "            try:\n",
    "                if int(line[0]) == 1:  # New line\n",
    "                    line_iter += 1\n",
    "            except ValueError:  # Some lines have periods in the index\n",
    "                line_iter += 1\n",
    "            writer.writerow([line_iter] + line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02193430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_value(preprocessed_data, file_type):\n",
    "\n",
    "    df = pd.read_csv('../data/clean_raw_'+file_type+'_data.tsv', sep='\\t', header=None , encoding = \"utf-8\",\n",
    "                     keep_default_na=False, quotechar='|', skip_blank_lines=False)\n",
    "\n",
    "    length = len(df.iloc[0].tolist())\n",
    "    for i in range(length-11):\n",
    "        row = i + 11 \n",
    "        df.iloc[:, row]= df.iloc[:, row].apply(lambda x: 'O' if x in ['', '_'] else x).tolist()\n",
    "        if row >=12:\n",
    "            df.iloc[:, row]= df.iloc[:, row].apply(lambda x: \"B-\"+x if x \n",
    "                                                   not in ['', 'O'] else x).tolist()  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "807646d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_csv_to_json(df, file_type):\n",
    "    \n",
    "    schemas = [] # set up container \n",
    "\n",
    "    # group sentence from sentences \n",
    "    sentences = df.groupby(0)\n",
    "\n",
    "    for group in sentences.groups:\n",
    "\n",
    "        sentence = sentences.get_group(group)\n",
    "        # from each sentence find the index of their verbs\n",
    "        verbs = sentence[sentence.iloc[:, 11] != 'O'].index\n",
    "\n",
    "        for count, verb in enumerate(verbs):\n",
    "            if count ==0:\n",
    "                V = \"V\"\n",
    "            else:\n",
    "                V = \"_\"\n",
    "\n",
    "            schema = {\n",
    "                'sep_words': sentence.iloc[:, 2].tolist(),\n",
    "                'BIO': sentence.iloc[:, 12].tolist(),\n",
    "                'pred_sense': [verb, df.iloc[verb, 11], V, df.iloc[verb, 5]]\n",
    "            }\n",
    "\n",
    "            schemas.append(schema)\n",
    "\n",
    "    \n",
    "    with open(\"../data/srl_univprop_en.\"+file_type+\".json\", 'w') as f:   \n",
    "        json.dump(schemas,f,indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "575beafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8355/2062762571.py:6: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  df = change_value(preprocessed_data, file)\n"
     ]
    }
   ],
   "source": [
    "file_type = ['train', 'dev']\n",
    "# if __name__ == '__main__':\n",
    "for file in file_type:\n",
    "    path  = \"../data/srl_univprop_en.\"+file+\".conll\"     \n",
    "    preprocessed_data = preprocessing_raw_data(path, file)\n",
    "    df = change_value(preprocessed_data, file)\n",
    "    from_csv_to_json(df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e9c9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
